"""Gemini MCP Server for Three.js Development

Claude ãŒãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼ã€Gemini ãŒãƒ—ãƒ­ã‚°ãƒ©ãƒãƒ¼ã¨ã—ã¦åˆ†æ¥­ã™ã‚‹ãŸã‚ã®MCPã‚µãƒ¼ãƒãƒ¼ã€‚
ã‚·ã‚§ãƒ¼ãƒ€ãƒ¼ã‚„è¦–è¦šçš„å“è³ªãŒé‡è¦ãªThree.jsã‚³ãƒ¼ãƒ‰ç”Ÿæˆã‚’Geminiã«å§”è¨—ã™ã‚‹ã€‚

Usage:
    uv run mcp_servers/gemini_threejs.py
"""

from mcp.server.fastmcp import FastMCP
import google.generativeai as genai
import os
import json
from pathlib import Path
from datetime import datetime

# .envã‹ã‚‰èª­ã¿è¾¼ã¿ï¼ˆpython-dotenvãŒã‚ã‚Œã°ä½¿ç”¨ï¼‰
try:
    from dotenv import load_dotenv
    # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã®.envã‚’æ¢ã™
    env_path = Path(__file__).parent.parent / ".env"
    if env_path.exists():
        load_dotenv(env_path)
except ImportError:
    pass  # dotenvãŒãªãã¦ã‚‚ç’°å¢ƒå¤‰æ•°ã‹ã‚‰èª­ã‚ã‚‹

# APIã‚­ãƒ¼è¨­å®š
GENAI_API_KEY = os.getenv("GEMINI_API_KEY")
if not GENAI_API_KEY:
    raise ValueError(
        "GEMINI_API_KEY not found. "
        "Set it in .env file or as environment variable."
    )

genai.configure(api_key=GENAI_API_KEY)
mcp = FastMCP("Gemini-ThreeJS-Assistant")

# åˆ©ç”¨å¯èƒ½ãªãƒ¢ãƒ‡ãƒ«
# https://ai.google.dev/gemini-api/docs/models
AVAILABLE_MODELS = {
    # Flashç³»ï¼ˆé«˜é€Ÿãƒ»ä½ã‚³ã‚¹ãƒˆï¼‰
    "flash": "gemini-2.0-flash",
    "flash-lite": "gemini-2.0-flash-lite-001",
    # Proç³»ï¼ˆé«˜å“è³ªï¼‰
    "pro": "gemini-2.5-pro",
    # Gemini 3
    "3-flash": "gemini-3-flash-preview",
    "3-pro": "gemini-3-pro-preview",
    "3.1-pro": "gemini-3.1-pro-preview",
}

# ãƒ¢ãƒ‡ãƒ«ã”ã¨ã®æ¨å®šã‚³ã‚¹ãƒˆï¼ˆå††/å›ï¼‰
MODEL_COSTS = {
    "flash": 0.07,
    "flash-lite": 0.02,
    "pro": 0.7,
    "3-flash": 0.12,
    "3-pro": 1.5,
    "3.1-pro": 2.0,
}

DEFAULT_MODEL = "flash"
MONTHLY_BUDGET = 1000  # å††
REQUEST_TIMEOUT_SECONDS = int(os.getenv("GEMINI_REQUEST_TIMEOUT", "120"))

# ä½¿ç”¨é‡è¨˜éŒ²ãƒ•ã‚¡ã‚¤ãƒ«
USAGE_FILE = Path(__file__).parent.parent / ".gemini_usage.json"

# kesson-spaceç”¨ã®ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ
KESSON_CONTEXT = """
ã‚ãªãŸã¯kesson-spaceãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®Three.jsã‚¨ã‚­ã‚¹ãƒ‘ãƒ¼ãƒˆã§ã™ã€‚

ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®ç‰¹å¾´:
- ã€Œæ¬ æé§†å‹•æ€è€ƒã€ã‚’è¦–è¦šåŒ–ã™ã‚‹3Dç©ºé–“
- é—‡ã®ä¸­ã«æµ®ã‹ã¶å…‰ï¼ˆæ¬ æï¼‰ã‚’è¡¨ç¾
- æ°´é¢ã€å‘¼å¸ã™ã‚‹ç©ºé–“ã€ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«è¼ªéƒ­
- ã‚·ã‚§ãƒ¼ãƒ€ãƒ¼ã«ã‚ˆã‚‹è¦–è¦šçš„å“è³ªãŒæœ€é‡è¦

æŠ€è¡“ã‚¹ã‚¿ãƒƒã‚¯:
- Three.js 0.160.0ï¼ˆES Modulesã€CDNï¼‰
- GLSL ã‚·ã‚§ãƒ¼ãƒ€ãƒ¼ï¼ˆsimplex noiseä½¿ç”¨ï¼‰
- ãƒ“ãƒ«ãƒ‰ãƒ„ãƒ¼ãƒ«ãªã—ï¼ˆGitHub Pagesç›´æ¥ãƒ‡ãƒ—ãƒ­ã‚¤ï¼‰

ã‚³ãƒ¼ãƒ‰ã‚¹ã‚¿ã‚¤ãƒ«:
- ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«åˆ†å‰²ï¼ˆscene.js, controls.js, navigation.jsï¼‰
- uniformã§ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿åˆ¶å¾¡
- uMixã«ã‚ˆã‚‹çŠ¶æ…‹é·ç§»ãƒ‘ã‚¿ãƒ¼ãƒ³
"""


def get_model(model_key: str) -> str:
    """ãƒ¢ãƒ‡ãƒ«ã‚­ãƒ¼ã‹ã‚‰å®Ÿéš›ã®ãƒ¢ãƒ‡ãƒ«åã‚’å–å¾—"""
    return AVAILABLE_MODELS.get(model_key, AVAILABLE_MODELS[DEFAULT_MODEL])


def get_model_key(model_key: str) -> str:
    """æ­£è¦åŒ–ã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã‚­ãƒ¼ã‚’å–å¾—"""
    return model_key if model_key in AVAILABLE_MODELS else DEFAULT_MODEL


def load_usage() -> dict:
    """ä½¿ç”¨é‡ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿"""
    if USAGE_FILE.exists():
        try:
            return json.loads(USAGE_FILE.read_text())
        except:
            pass
    return {"calls": []}


def save_usage(data: dict):
    """ä½¿ç”¨é‡ãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜"""
    USAGE_FILE.write_text(json.dumps(data, indent=2, ensure_ascii=False))


def record_usage(model_key: str, tool_name: str):
    """APIå‘¼ã³å‡ºã—ã‚’è¨˜éŒ²"""
    data = load_usage()
    data["calls"].append({
        "timestamp": datetime.now().isoformat(),
        "model": model_key,
        "tool": tool_name,
        "cost": MODEL_COSTS.get(model_key, 0.07)
    })
    save_usage(data)


@mcp.tool()
def get_usage() -> str:
    """
    Gemini APIä½¿ç”¨é‡ã‚’è¡¨ç¤ºï¼ˆä»Šæœˆã®ä½¿ç”¨å›æ•°ãƒ»æ¨å®šã‚³ã‚¹ãƒˆï¼‰
    """
    data = load_usage()
    calls = data.get("calls", [])
    
    # ä»Šæœˆã®ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ•ã‚£ãƒ«ã‚¿
    now = datetime.now()
    current_month = now.strftime("%Y-%m")
    monthly_calls = [c for c in calls if c["timestamp"].startswith(current_month)]
    
    # ãƒ¢ãƒ‡ãƒ«åˆ¥é›†è¨ˆ
    model_stats = {}
    total_cost = 0
    for call in monthly_calls:
        model = call.get("model", "unknown")
        cost = call.get("cost", 0.07)
        if model not in model_stats:
            model_stats[model] = {"count": 0, "cost": 0}
        model_stats[model]["count"] += 1
        model_stats[model]["cost"] += cost
        total_cost += cost
    
    # å‡ºåŠ›ç”Ÿæˆ
    lines = [
        f"ğŸ“Š Gemini API ä½¿ç”¨é‡ ({current_month})",
        f"{'=' * 40}",
        "",
        f"ğŸ’° æœˆé–“äºˆç®—: Â¥{MONTHLY_BUDGET:,}",
        f"ğŸ’¸ ä½¿ç”¨æ¸ˆã¿: Â¥{total_cost:,.1f} ({total_cost/MONTHLY_BUDGET*100:.1f}%)",
        f"ğŸ“ˆ æ®‹ã‚Š: Â¥{MONTHLY_BUDGET - total_cost:,.1f}",
        "",
        f"ğŸ“ ç·å‘¼ã³å‡ºã—å›æ•°: {len(monthly_calls)}å›",
        "",
        "ãƒ¢ãƒ‡ãƒ«åˆ¥:",
    ]
    
    for model, stats in sorted(model_stats.items()):
        lines.append(f"  {model}: {stats['count']}å› (Â¥{stats['cost']:.1f})")
    
    if not model_stats:
        lines.append("  ï¼ˆä»Šæœˆã®ä½¿ç”¨ãªã—ï¼‰")
    
    lines.extend([
        "",
        "ã‚³ã‚¹ãƒˆç›®å®‰:",
        f"  flash: Â¥{MODEL_COSTS['flash']}/å›",
        f"  flash-lite: Â¥{MODEL_COSTS['flash-lite']}/å›",
        f"  pro: Â¥{MODEL_COSTS['pro']}/å›",
        f"  3-flash: Â¥{MODEL_COSTS['3-flash']}/å›",
    ])
    
    return "\n".join(lines)


@mcp.tool()
def reset_usage() -> str:
    """
    ä½¿ç”¨é‡ãƒ‡ãƒ¼ã‚¿ã‚’ãƒªã‚»ãƒƒãƒˆï¼ˆæ–°ã—ã„æœˆã®é–‹å§‹æ™‚ãªã©ï¼‰
    """
    save_usage({"calls": []})
    return "âœ… ä½¿ç”¨é‡ãƒ‡ãƒ¼ã‚¿ã‚’ãƒªã‚»ãƒƒãƒˆã—ã¾ã—ãŸ"


@mcp.tool()
def generate_threejs_code(
    task_description: str,
    model: str = "flash",
    optimization_level: str = "standard",
    include_kesson_context: bool = True
) -> str:
    """
    Geminiã§Three.jsã‚³ãƒ¼ãƒ‰ã‚’ç”Ÿæˆ
    
    Args:
        task_description: å®Ÿè£…ã—ãŸã„Three.jsã®æ©Ÿèƒ½èª¬æ˜
        model: ä½¿ç”¨ãƒ¢ãƒ‡ãƒ« ("flash", "flash-lite", "pro", "3-flash")
        optimization_level: "standard" or "advanced"
        include_kesson_context: kesson-spaceã®ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’å«ã‚ã‚‹ã‹
    """
    context = KESSON_CONTEXT if include_kesson_context else ""
    model_key = get_model_key(model)
    model_name = get_model(model)
    
    prompt = f"""
{context}

ä»¥ä¸‹ã®è¦ä»¶ã«åŸºã¥ã„ã¦ã€é«˜å“è³ªãªThree.jsã‚³ãƒ¼ãƒ‰ã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚

è¦ä»¶: {task_description}
æœ€é©åŒ–ãƒ¬ãƒ™ãƒ«: {optimization_level}

ã‚³ãƒ¼ãƒ‰ã«ã¯ä»¥ä¸‹ã‚’å«ã‚ã¦ãã ã•ã„:
- é©åˆ‡ãªã‚³ãƒ¡ãƒ³ãƒˆï¼ˆæ—¥æœ¬èªå¯ï¼‰
- ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–
- ã‚·ã‚§ãƒ¼ãƒ€ãƒ¼ã‚’ä½¿ã†å ´åˆã¯GLSLã‚’åŸ‹ã‚è¾¼ã¿
- ES Moduleså½¢å¼ï¼ˆimport/exportï¼‰
"""
    
    try:
        gemini = genai.GenerativeModel(model_name)
        response = gemini.generate_content(
            prompt,
            request_options={"timeout": REQUEST_TIMEOUT_SECONDS},
        )
        
        # ä½¿ç”¨é‡ã‚’è¨˜éŒ²
        record_usage(model_key, "generate_threejs_code")
        
        if not response.text:
            return "Geminiã‹ã‚‰æœ‰åŠ¹ãªå›ç­”ãŒå¾—ã‚‰ã‚Œã¾ã›ã‚“ã§ã—ãŸã€‚"
        
        return f"[Model: {model_name}]\n\n{response.text}"
        
    except Exception as e:
        return f"Gemini APIã‚¨ãƒ©ãƒ¼: {type(e).__name__}: {str(e)}"


@mcp.tool()
def generate_shader(
    shader_description: str,
    model: str = "flash",
    shader_type: str = "fragment"
) -> str:
    """
    GLSLã‚·ã‚§ãƒ¼ãƒ€ãƒ¼ã‚³ãƒ¼ãƒ‰ã‚’ç”Ÿæˆ
    
    Args:
        shader_description: ã‚·ã‚§ãƒ¼ãƒ€ãƒ¼ã§å®Ÿç¾ã—ãŸã„è¦–è¦šåŠ¹æœ
        model: ä½¿ç”¨ãƒ¢ãƒ‡ãƒ« ("flash", "flash-lite", "pro", "3-flash")
        shader_type: "vertex", "fragment", or "both"
    """
    model_key = get_model_key(model)
    model_name = get_model(model)
    
    prompt = f"""
{KESSON_CONTEXT}

ä»¥ä¸‹ã®è¦–è¦šåŠ¹æœã‚’å®Ÿç¾ã™ã‚‹GLSLã‚·ã‚§ãƒ¼ãƒ€ãƒ¼ã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚

åŠ¹æœ: {shader_description}
ã‚·ã‚§ãƒ¼ãƒ€ãƒ¼ã‚¿ã‚¤ãƒ—: {shader_type}

è¦ä»¶:
- simplex noiseã‚’ä½¿ç”¨å¯ï¼ˆé–¢æ•°ã¯åˆ¥é€”æä¾›ã•ã‚Œã¦ã„ã‚‹å‰æï¼‰
- Three.jsã®ShaderMaterialç”¨
- uniformsã®å®šç¾©ã‚‚å«ã‚ã‚‹
- ç¾ã—ã•ã¨æ»‘ã‚‰ã‹ã•ã‚’æœ€å„ªå…ˆ
"""
    
    try:
        gemini = genai.GenerativeModel(model_name)
        response = gemini.generate_content(
            prompt,
            request_options={"timeout": REQUEST_TIMEOUT_SECONDS},
        )
        
        # ä½¿ç”¨é‡ã‚’è¨˜éŒ²
        record_usage(model_key, "generate_shader")
        
        return f"[Model: {model_name}]\n\n{response.text}" if response.text else "ã‚·ã‚§ãƒ¼ãƒ€ãƒ¼ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸã€‚"
    except Exception as e:
        return f"ã‚¨ãƒ©ãƒ¼: {str(e)}"


@mcp.tool()
def review_threejs_code(
    code: str,
    model: str = "flash",
    focus_areas: str = "visual quality, performance, shader optimization"
) -> str:
    """
    Three.jsã‚³ãƒ¼ãƒ‰ã‚’Geminiã§ãƒ¬ãƒ“ãƒ¥ãƒ¼
    
    Args:
        code: ãƒ¬ãƒ“ãƒ¥ãƒ¼ã™ã‚‹ã‚³ãƒ¼ãƒ‰
        model: ä½¿ç”¨ãƒ¢ãƒ‡ãƒ« ("flash", "flash-lite", "pro", "3-flash")
        focus_areas: ãƒ¬ãƒ“ãƒ¥ãƒ¼ã®ç„¦ç‚¹
    """
    model_key = get_model_key(model)
    model_name = get_model(model)
    
    prompt = f"""
{KESSON_CONTEXT}

ä»¥ä¸‹ã®Three.jsã‚³ãƒ¼ãƒ‰ã‚’ãƒ¬ãƒ“ãƒ¥ãƒ¼ã—ã¦ãã ã•ã„ã€‚

ãƒ¬ãƒ“ãƒ¥ãƒ¼è¦³ç‚¹: {focus_areas}

ã‚³ãƒ¼ãƒ‰:
```javascript
{code}
```

ä»¥ä¸‹ã®ç‚¹ã‚’åˆ†æã—ã¦ãã ã•ã„:
1. è¦–è¦šçš„å“è³ªã®æ”¹å–„ç‚¹
2. ã‚·ã‚§ãƒ¼ãƒ€ãƒ¼ã®æœ€é©åŒ–
3. ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã®å•é¡Œ
4. kesson-spaceã®ã‚³ãƒ³ã‚»ãƒ—ãƒˆã¨ã®æ•´åˆæ€§
"""
    
    try:
        gemini = genai.GenerativeModel(model_name)
        response = gemini.generate_content(
            prompt,
            request_options={"timeout": REQUEST_TIMEOUT_SECONDS},
        )
        
        # ä½¿ç”¨é‡ã‚’è¨˜éŒ²
        record_usage(model_key, "review_threejs_code")
        
        return f"[Model: {model_name}]\n\n{response.text}" if response.text else "ãƒ¬ãƒ“ãƒ¥ãƒ¼çµæœã‚’å–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚"
    except Exception as e:
        return f"ã‚¨ãƒ©ãƒ¼: {str(e)}"


@mcp.tool()
def compare_implementations(
    task: str,
    claude_code: str,
    model: str = "pro"
) -> str:
    """
    Claudeã®ã‚³ãƒ¼ãƒ‰ã¨ã®æ¯”è¼ƒï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯Proï¼‰
    
    Args:
        task: å®Ÿè£…ã‚¿ã‚¹ã‚¯ã®èª¬æ˜
        claude_code: ClaudeãŒç”Ÿæˆã—ãŸã‚³ãƒ¼ãƒ‰
        model: ä½¿ç”¨ãƒ¢ãƒ‡ãƒ« ("flash", "flash-lite", "pro", "3-flash")
    """
    model_key = get_model_key(model)
    model_name = get_model(model)
    
    prompt = f"""
{KESSON_CONTEXT}

ä»¥ä¸‹ã®ã‚¿ã‚¹ã‚¯ã«å¯¾ã—ã¦ã€åˆ¥ã®AIï¼ˆClaudeï¼‰ãŒç”Ÿæˆã—ãŸã‚³ãƒ¼ãƒ‰ãŒã‚ã‚Šã¾ã™ã€‚
ã‚ãªãŸï¼ˆGeminiï¼‰ã‚‚åŒã˜ã‚¿ã‚¹ã‚¯ã‚’å®Ÿè£…ã—ã€ä¸¡è€…ã‚’æ¯”è¼ƒã—ã¦ãã ã•ã„ã€‚

ã‚¿ã‚¹ã‚¯: {task}

Claudeã®ã‚³ãƒ¼ãƒ‰:
```javascript
{claude_code}
```

ä»¥ä¸‹ã‚’æä¾›ã—ã¦ãã ã•ã„:
1. ã‚ãªãŸã®å®Ÿè£…æ¡ˆï¼ˆè¦–è¦šçš„å“è³ªã‚’æœ€å„ªå…ˆï¼‰
2. ä¸¡è€…ã®æ¯”è¼ƒï¼ˆç‰¹ã«ã‚·ã‚§ãƒ¼ãƒ€ãƒ¼å“è³ªï¼‰
3. æ¨å¥¨ï¼šã©ã¡ã‚‰ã‚’ãƒ™ãƒ¼ã‚¹ã«ã™ã¹ãã‹
"""
    
    try:
        gemini = genai.GenerativeModel(model_name)
        response = gemini.generate_content(
            prompt,
            request_options={"timeout": REQUEST_TIMEOUT_SECONDS},
        )
        
        # ä½¿ç”¨é‡ã‚’è¨˜éŒ²
        record_usage(model_key, "compare_implementations")
        
        return f"[Model: {model_name}]\n\n{response.text}" if response.text else "æ¯”è¼ƒçµæœã‚’å–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚"
    except Exception as e:
        return f"ã‚¨ãƒ©ãƒ¼: {str(e)}"


@mcp.tool()
def list_models() -> str:
    """
    åˆ©ç”¨å¯èƒ½ãªGeminiãƒ¢ãƒ‡ãƒ«ä¸€è¦§ã‚’è¡¨ç¤º
    """
    lines = ["åˆ©ç”¨å¯èƒ½ãªãƒ¢ãƒ‡ãƒ«:", ""]
    for key, model in AVAILABLE_MODELS.items():
        cost = MODEL_COSTS.get(key, 0.07)
        default = " (default)" if key == DEFAULT_MODEL else ""
        lines.append(f"  {key}: {model} â€” Â¥{cost}/å›{default}")
    
    lines.extend([
        "",
        "ä½¿ç”¨ä¾‹:",
        '  generate_threejs_code(task="...", model="pro")',
        '  generate_shader(shader_description="...", model="3-flash")',
        "",
        "ä½¿ç”¨é‡ç¢ºèª:",
        "  get_usage() â€” ä»Šæœˆã®ä½¿ç”¨çŠ¶æ³ã‚’è¡¨ç¤º",
    ])
    
    return "\n".join(lines)


if __name__ == "__main__":
    mcp.run()
